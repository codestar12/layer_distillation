{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0420 21:30:48.923893 140361278195520 hdf5_format.py:261] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "\n",
    "num_predictions = 20\n",
    "\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model = load_model('./combined.h5')\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 406us/sample - loss: 0.7819 - accuracy: 0.8640\n",
      "Test loss: 0.7818754182875156\n",
      "Test accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 31,817,034\n",
      "Trainable params: 31,814,986\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "10\n",
      "11\n",
      "12\n",
      "14\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(conf['layers']):\n",
    "    if layer['class_name'] == 'Conv2D':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_output = tf.keras.Model(inputs=model.input, outputs=[model.layers[14].output, model.layers[15].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "=================================================================\n",
      "Total params: 12,354,880\n",
      "Trainable params: 12,354,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_output.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_output(x_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "dataset_test = dataset.batch(batch_size)\n",
    "dataset_test = dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 2, 2, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output.output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=get_output.output[0].shape[1::])\n",
    "X = tf.keras.layers.SeparableConv2D(filters=get_output.output[1].shape[-1], kernel_size= (3,3), padding='Same')(inputs)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.ReLU()(X)\n",
    "X = tf.keras.layers.SeparableConv2D(filters=get_output.output[1].shape[-1], kernel_size=(3,3), padding='Same')(X)\n",
    "X = tf.keras.layers.BatchNormalization()(X)\n",
    "X = tf.keras.layers.ReLU()(X)\n",
    "replacement_layers = tf.keras.Model(inputs=inputs, outputs=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2, 2, 512)]       0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 2, 2, 512)         0         \n",
      "=================================================================\n",
      "Total params: 538,624\n",
      "Trainable params: 536,576\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "replacement_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=.001)\n",
    "\n",
    "loss_object = tf.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers.compile(loss=loss_object, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class LayerBatch(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, input_model, dataset):\n",
    "        self.input_model = input_model\n",
    "        self.dataset = dataset.__iter__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(50000 / 32)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.input_model(next(self.dataset))\n",
    "        return X, y\n",
    "    \n",
    "import math\n",
    "class LayerTest(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, input_model, dataset):\n",
    "        self.input_model = input_model\n",
    "        self.dataset = dataset.__iter__()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return math.ceil(10000 / 32)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.input_model(next(self.dataset))\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = tf.keras.callbacks.ModelCheckpoint('./replacement_layers_3_batch_relu.h5', verbose=1, save_weights_only=True, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = LayerBatch(get_output, dataset)\n",
    "test_gen = LayerTest(get_output, dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00061, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00061 to 0.00029, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00029\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00029 to 0.00026, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00026 to 0.00025, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00025 to 0.00024, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00024 to 0.00021, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00021\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00021 to 0.00021, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00021 to 0.00020, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00020\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00020 to 0.00017, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.00017\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00017 to 0.00017, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00017 to 0.00016, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00016\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00016 to 0.00015, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00015\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00015\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00015 to 0.00015, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00015\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00015 to 0.00014, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00014\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00014 to 0.00013, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00013\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00013 to 0.00012, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00012\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00012\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00012\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00012\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00012 to 0.00011, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00011\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00011\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00011\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00011\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00011\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00011\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00011 to 0.00011, saving model to ./replacement_layers_3_batch_relu.h5\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7203b48d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_layers.fit_generator(generator=train_gen, epochs=50, validation_data=test_gen ,verbose=0, callbacks=[save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_json = replacement_layers.to_json()\n",
    "with open('replacement_layers_3_batch_relu.json', 'w') as json_file:\n",
    "    json_file.write(replacement_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del replacement_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('replacement_layers_3_batch_relu.json', 'r') as json_file:\n",
    "    replacement_layers = tf.keras.models.model_from_json(json_file.read())\n",
    "\n",
    "replacement_layers.load_weights('replacement_layers_3_batch_relu.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_layers.compile(loss=loss_object, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011921932925648702"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_layers.evaluate_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_output = tf.keras.Model(inputs=model.input, outputs=[model.layers[14].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "=================================================================\n",
      "Total params: 9,995,072\n",
      "Trainable params: 9,995,072\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "get_output.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_joint = tf.keras.Model(inputs=get_output.input, outputs=replacement_layers(get_output.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 2, 2, 512)         538624    \n",
      "=================================================================\n",
      "Total params: 10,533,696\n",
      "Trainable params: 10,531,648\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_joint.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_half = tf.keras.Sequential()\n",
    "for layer in model.layers[16::]:\n",
    "    bottom_half.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_half.build(input_shape=new_joint.output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d_2 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 19,462,154\n",
      "Trainable params: 19,460,106\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bottom_half.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = tf.keras.Model(inputs=new_joint.input, outputs=bottom_half(new_joint.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 2, 2, 512)         538624    \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 10)                19462154  \n",
      "=================================================================\n",
      "Total params: 29,995,850\n",
      "Trainable params: 10,531,648\n",
      "Non-trainable params: 19,464,202\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined.layers[-1].trainable=False\n",
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 31,817,034\n",
      "Trainable params: 31,814,986\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 295us/sample - loss: 0.7819 - accuracy: 0.8640\n",
      "Test loss: 0.7818754182875156\n",
      "Test accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "del bottom_half, new_joint, replacement_layers, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 294us/sample - loss: 0.7708 - accuracy: 0.8623\n",
      "Test loss: 0.7707621360957623\n",
      "Test accuracy: 0.8623\n"
     ]
    }
   ],
   "source": [
    "scores = combined.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_combined = tf.keras.Sequential()\n",
    "new_layers = []\n",
    "new_combined.add(tf.keras.layers.Input(shape=(32,32,3)))\n",
    "accum = 0\n",
    "for layer in combined.layers:\n",
    "    if hasattr(layer, 'layers'):\n",
    "        for sublayer in layer.layers:\n",
    "            if(sublayer.__class__.__name__ != 'InputLayer'): \n",
    "                new_layers.append((sublayer.__class__.__name__, sublayer.get_config(), accum))\n",
    "            accum += 1\n",
    "    else:\n",
    "        \n",
    "        new_layers.append((layer.__class__.__name__, layer.get_config(), accum))\n",
    "        accum += 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, layer in enumerate(new_layers):\n",
    "    new_combined.add(keras.layers.deserialize(\n",
    "                            {'class_name': layer[0], \n",
    "                             'config': layer[1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_combined.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa7f6c177f0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7f6c17dd8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7f6c2eba8>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa7ee6b20f0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7ed9ea8d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7eda04ac8>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa7eda0bbe0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7ed9a8550>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7ed9a8d68>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7ed9bd6d8>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa7c874ac50>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7ed9bde48>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7c8761dd8>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7c877ac88>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa7c87079b0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa7c871e8d0>\n",
      "16 sub is <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa7482446d8> new is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa7100e1d30>\n",
      "16 sub is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa748249438> new is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa7100e1d30>\n",
      "17 sub is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa72034a7b8> new is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa710133b70>\n",
      "18 sub is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa748247080> new is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa710045a20>\n",
      "19 sub is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa748247e10> new is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa710095860>\n",
      "20 sub is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa76c467128> new is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa520200fd0>\n",
      "21 sub is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa76c467470> new is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa710080eb8>\n",
      "22 sub is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa7c86cbac8> new is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa520218fd0>\n",
      "23 sub is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa7ed9c9a20> new is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa7101a3b38>\n",
      "24 sub is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa7c86c1eb8> new is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa520156fd0>\n",
      "25 sub is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa7c86fd208> new is <tensorflow.python.keras.layers.convolutional.SeparableConv2D object at 0x7fa710164e80>\n",
      "26 sub is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa7c874ae48> new is <tensorflow.python.keras.layers.normalization.BatchNormalizationV2 object at 0x7fa520088cc0>\n",
      "27 sub is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa7ee68ccc0> new is <tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7fa71018de48>\n",
      "28 sub is <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa7c869e940> new is <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa520098fd0>\n",
      "29 sub is <tensorflow.python.keras.layers.core.Flatten object at 0x7fa7c8563cc0> new is <tensorflow.python.keras.layers.core.Flatten object at 0x7fa520016390>\n",
      "30 sub is <tensorflow.python.keras.layers.core.Dense object at 0x7fa7c850d0f0> new is <tensorflow.python.keras.layers.core.Dense object at 0x7fa520032d30>\n",
      "31 sub is <tensorflow.python.keras.layers.core.Dense object at 0x7fa7c850d908> new is <tensorflow.python.keras.layers.core.Dense object at 0x7fa4f87cb5f8>\n",
      "32 sub is <tensorflow.python.keras.layers.core.Dense object at 0x7fa7c8528d68> new is <tensorflow.python.keras.layers.core.Dense object at 0x7fa4f87e4390>\n"
     ]
    }
   ],
   "source": [
    "accum = 0\n",
    "for i, layer in enumerate(combined.layers):\n",
    "    if hasattr(layer, 'layers'):\n",
    "        \n",
    "        for sublayer in layer.layers:\n",
    "            print(f'{accum} sub is {sublayer} new is {new_combined.layers[accum]}')\n",
    "            if(sublayer.__class__.__name__ != 'InputLayer'):              \n",
    "                new_combined.layers[accum].set_weights(sublayer.get_weights())\n",
    "                accum += 1\n",
    "#             else:\n",
    "#                 accum += 1\n",
    "        continue\n",
    "    else:\n",
    "        print(layer)\n",
    "        new_combined.layers[accum].set_weights(layer.get_weights())\n",
    "        accum +=1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_combined.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "del combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_save=tf.keras.callbacks.ModelCheckpoint('./refactor_finetune.h5', verbose=1, save_weights_only=False, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "49952/50000 [============================>.] - ETA: 0s - loss: 0.0710 - accuracy: 0.9824\n",
      "Epoch 00001: val_loss improved from inf to 1.00729, saving model to ./refactor_finetune.h5\n",
      "50000/50000 [==============================] - 68s 1ms/sample - loss: 0.0709 - accuracy: 0.9824 - val_loss: 1.0073 - val_accuracy: 0.8622\n",
      "Epoch 2/3\n",
      "49952/50000 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9833\n",
      "Epoch 00002: val_loss did not improve from 1.00729\n",
      "50000/50000 [==============================] - 66s 1ms/sample - loss: 0.0730 - accuracy: 0.9833 - val_loss: 1.1739 - val_accuracy: 0.8641\n",
      "Epoch 3/3\n",
      "49984/50000 [============================>.] - ETA: 0s - loss: 0.0769 - accuracy: 0.9839\n",
      "Epoch 00003: val_loss did not improve from 1.00729\n",
      "50000/50000 [==============================] - 67s 1ms/sample - loss: 0.0769 - accuracy: 0.9839 - val_loss: 1.1311 - val_accuracy: 0.8553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa488753f98>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_combined.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), epochs=3, callbacks=[new_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_1 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_2 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 2, 2, 512)         267264    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v2_3 (Ba (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 29,995,850\n",
      "Trainable params: 29,991,754\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_combined.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "combined_json = new_combined.to_json()\n",
    "with open('necombined.json', 'w') as json_file:\n",
    "    json_file.write(combined_json)\n",
    "new_combined.save_weights('combined.h5')\n",
    "#del combined\n",
    "with open('combined.json', 'r') as json_file:\n",
    "    json = json_file.read()\n",
    "    \n",
    "combined_two = tf.keras.models.model_from_json(json)\n",
    "combined_two.build(input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "combined.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(combined.layers)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_combined.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores = new_combined.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_combined.save('combined.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "new_combined.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "combined_two.layers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "combined.layers[2].layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
